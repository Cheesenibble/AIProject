{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"fQMwRnY-DCih"},"outputs":[],"source":["#import library (tensorflow bc it says its good for image recognition meaning it can tell for differences in between images)\n","#https://www.nvidia.com/en-au/glossary/tensorflow/#:~:text=TensorFlow%20can%20be%20used%20to,such%20as%20partial%20differential%20equations.\n","import tensorflow as tf\n","\n","#Keras (api we use) we can change if needed\n","\n","#keras.models is where we get the type of model we use (Sequential)\n","#https://keras.io/api/models/\n","from tensorflow.keras.models import Sequential\n","\n","#keras.layers is the type of layers\n","#https://keras.io/api/layers/   and use this link for details abt dense,flatten, and dropout    https://datascience.stackexchange.com/questions/44124/when-to-use-dense-conv1-2d-dropout-flatten-and-all-the-other-layers\n","from tensorflow.keras.layers import Dense, Flatten, Dropout\n","\n","#below is a example model\n","#from tensorflow.keras.applications import ResNet50 (CNN model) bc it says it is a visual recognicition model when i searched it up. https://keras.io/api/applications/ (gives a list of models keras uses)\n","#https://wandb.ai/mostafaibrahim17/ml-articles/reports/The-Basics-of-ResNet50---Vmlldzo2NDkwNDE2#:~:text=ResNet50%20is%20a%20deep%20learning,model%20is%2050%20layers%20deep.\n","from tensorflow.keras.applications import ResNet50\n","\n","#allows to rescale images and enhances different features over consecutive trials for the ai model(for it to tell differences)\n","#https://www.isahit.com/blog/what-is-the-purpose-of-image-preprocessing-in-deep-learning#:~:text=Even%20though%20geometric%20transformations%20of,features%20crucial%20for%20subsequent%20processing.\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","#chatgpt said to use this for some reason but I only see it allows us to stop our model during training.\n","from tensorflow.keras.callbacks import EarlyStopping"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VY4jWXoMJ4Hv"},"outputs":[],"source":["from google.colab import files"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"s9sLsfURQ0QO","outputId":"450efa5e-8801-4b65-b187-f6a5543c6e71"},"outputs":[{"data":{"text/html":["\n","     <input type=\"file\" id=\"files-9ba17eb2-ffb3-483f-8568-cc7e8ac69589\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-9ba17eb2-ffb3-483f-8568-cc7e8ac69589\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["uploaded = files.upload()"]},{"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse"],"metadata":{"id":"GPDyI27F5I23"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":298,"status":"error","timestamp":1736645381436,"user":{"displayName":"Cheese","userId":"14393660696254717761"},"user_tz":300},"id":"pfFpDUABG22S","outputId":"64719f90-a924-4c00-ae03-0cc3746f13f0"},"outputs":[{"ename":"NameError","evalue":"name 'Users' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-829a143a599e>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#need images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#also note that there should be two folders in the training images/test images (ai and human made images just name the folder depending on each one)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainImages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUsers\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0merich\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mDownloads\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0maiTrainingImages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#need images for this part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Users' is not defined"]}],"source":["#self explainitory just replace path/to/____ with the file path\n","\n","#need images\n","#also note that there should be two folders in the training images/test images (ai and human made images just name the folder depending on each one)\n","trainImages = Users/erich/Downloads/aiTrainingImages\n","\n","#need images for this part\n","#note that there should NOT be two folders for testing data\n","testImages = Users/erich/Downloads/aiTestImages"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":98,"status":"error","timestamp":1736645339146,"user":{"displayName":"Cheese","userId":"14393660696254717761"},"user_tz":300},"id":"LR-XxRInHAVr","outputId":"9eed693a-41de-4e0b-cfcb-0dd4a91a53ca"},"outputs":[{"ename":"NameError","evalue":"name 'ImageDataGenerator' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-5fde7c0efdeb>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#link below gives list of possible values although I didn't use all of them ex:brightness, zoom, etc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#https://towardsdatascience.com/exploring-image-data-augmentation-with-keras-and-tensorflow-a8162d89b844\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m train_dataGenerator = ImageDataGenerator(\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#https://github.com/Arsey/keras-transfer-learning-for-oxford102/issues/1 (this is the reason why we rescale to 1./255)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"]}],"source":["#this is what allows us to change how the ai will see the image\n","#link below gives list of possible values although I didn't use all of them ex:brightness, zoom, etc\n","#https://towardsdatascience.com/exploring-image-data-augmentation-with-keras-and-tensorflow-a8162d89b844\n","train_dataGenerator = ImageDataGenerator(\n","\n","    #https://github.com/Arsey/keras-transfer-learning-for-oxford102/issues/1 (this is the reason why we rescale to 1./255)\n","    rescale=1./255,\n","\n","    #during training the image can roate up to 30 degrees (you can change this value if you want up to 360 i think)\n","    rotation_range=30,\n","\n","    #self explainatory, allows more \"data images\" with a limited set because we can move the image in all 4 directions, look at link below for examples\n","    #https://stackoverflow.com/questions/62484597/understanding-width-shift-range-and-height-shift-range-arguments-in-kerass\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","\n","    #similar to width/height shift range but it distorts the image instead of moving it\n","    #https://stackoverflow.com/questions/57301330/what-exactly-the-shear-do-in-imagedatagenerator-of-keras\n","    shear_range=0.2,\n","\n","    #magnification range\n","    zoom_range=0.2,\n","\n","    #it can flip the image\n","    horizontal_flip=True,\n","\n","    #its the method used to fill the empty pixals(like for example we shift the image a bit to the right we have empty pixels on the left) although I don't get how it works\n","    fill_mode='nearest')\n","\n","#we don't need any otherthing besides rescaling bc its the testing data set\n","test_datagen = ImageDataGenerator(rescale=1./255)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":2,"status":"error","timestamp":1736645309888,"user":{"displayName":"Cheese","userId":"14393660696254717761"},"user_tz":300},"id":"uNrq3Tm9Igpl","outputId":"f0c8ce44-ac13-4e6f-e31d-2127d9fd54d7"},"outputs":[{"ename":"NameError","evalue":"name 'train_dataGenerator' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-f0a8e31df752>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#theres a error bc its unable to find the file btw (its saying something abt a naming error but I'm really hoping that adding images to our training data and testing data will fix this)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_generator = train_dataGenerator.flow_from_directory(\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#its the path to the training images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrainImages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_dataGenerator' is not defined"]}],"source":["#theres a error bc its unable to find the file btw (its saying something abt a naming error but I'm really hoping that adding images to our training data and testing data will fix this)\n","train_generator = train_dataGenerator.flow_from_directory(\n","\n","    #its the path to the training images\n","    trainImages,\n","\n","    #it has to be (224,224) because resnet50 uses 244,244\n","    target_size=(224, 224),\n","\n","    #the number of images for each training run (this case its 25 but you can change depending on choice)\n","    batch_size=25,\n","\n","    #we are classifiying based on true or false so we can use binary as our classifiction mode (0 for ai, 1 for human or you can swap it)\n","    class_mode='binary')\n","\n","#btw .flow_from_directory has 3 requirements to work, 1: the root directory must have 2 folders(1 for training, 1 for testing), 2: the training folder should have a amount of sub directoies depending on what we are training on (our case its ai/human so two sub dierctories)\n","#3: training folder should only contain the test images\n","#https://studymachinelearning.com/keras-imagedatagenerator-with-flow_from_directory/#:~:text=The%20flow_from_directory()%20method%20takes,are%20using%20flow_from_directory()%20method.\n","test_generator = test_datagen.flow_from_directory(\n","\n","    #path to test images\n","    testImages,\n","\n","    #the rest is the same you get it (i just changed batch size to 50)\n","    target_size=(224, 224),\n","    batch_size=50,\n","    class_mode='binary')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2652,"status":"ok","timestamp":1735773563011,"user":{"displayName":"Cheese","userId":"14393660696254717761"},"user_tz":300},"id":"YI2VSY8KIhLW","outputId":"65b907c2-19a9-4711-f3c2-fcd44cc8f644"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}],"source":["#imagenet is us using pre-trained weigths from ImageNet(which are created using other datasets)\n","#IMPORTANT, note that I think google colab has accecss to the ImageNet database but I don't myself (im requesting access still)\n","#include_top=flase means that we remove the top layer of the model aka it allows us to use our own inputs for the model as well as controlling the output while being able to use the already exisiting weights from ImageNet.\n","#the input_shape is just (width, height, and rgb(3 means all 3 colors))\n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H0YJFibKIi1j"},"outputs":[],"source":["#it means that the ResNet50 model cant be modified when we train our own model(meaning the layers that resnet50 uses wont be changed)\n","base_model.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WBjQGJLrIl2t"},"outputs":[],"source":["#BTW THIS IS WHERE OUR OWN MODEL IS MADE, each line is a new layer, ex: base_model, flatten, dense, and the others its why we rename sequential into 'model'\n","\n","#also to note the Sequential is the type of model we use\n","#link for a bit of explainition on sequential model    https://www.tensorflow.org/guide/keras/sequential_model\n","model = Sequential([\n","\n","    #the pretrained model\n","    base_model,\n","\n","    #layers\n","    Flatten(),\n","    Dense(512, activation='relu'),\n","    Dropout(0.5),\n","\n","    #it classifiys the output into either 0 or 1 (final layer which is the classification one)\n","    Dense(1, activation='sigmoid')\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AwbGZGbrInNW"},"outputs":[],"source":["#compile model, meaning we find the values we need for science fair\n","#also we need to compile model in order for it to convert its data into things we can understand\n","#chat gpt the things im getting lazy\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jN_U_zHaIocf"},"outputs":[],"source":["#summary, early stopping stops the model if there is no improvement, monitor is self explainatory(it looks for only 'val_loss', patience is the number of epochs that have to be the same,\n","# and restore best weights mean that before it stops it picks the best layer)\n","early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":88,"status":"error","timestamp":1735773589859,"user":{"displayName":"Cheese","userId":"14393660696254717761"},"user_tz":300},"id":"9lt88EtGIqKt","outputId":"e8dd86fe-a437-43b2-f015-e823dc6d26fc"},"outputs":[{"ename":"NameError","evalue":"name 'train_generator' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-a124c9c2df85>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#error bc in previous code it is doesn't exist atm (please i need help with this line train_generator = train_dataGenerator.flow_from_directory(  its actually ruining the rest of the code).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#// is the divide operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_generator' is not defined"]}],"source":["history = model.fit(\n","\n","    #error bc in previous code it is doesn't exist atm (please i need help with this line train_generator = train_dataGenerator.flow_from_directory(  its actually ruining the rest of the code).\n","    train_generator,\n","\n","    #// is the divide operator\n","    #and look here for epoch explaination https://www.geeksforgeeks.org/epoch-in-machine-learning/\n","    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n","    epochs=10,\n","    validation_data=test_generator,\n","    validation_steps=test_generator.samples // test_generator.batch_size,\n","    callbacks=[early_stopping])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZMNx1w9qIrqb"},"outputs":[],"source":["#it just saves the model\n","model.save('ScienceFair.keras')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"elapsed":2,"status":"error","timestamp":1735773596330,"user":{"displayName":"Cheese","userId":"14393660696254717761"},"user_tz":300},"id":"kKOmtvp1ItAq","outputId":"2a7d6f97-b1b9-4f7a-d38f-b06eb8568fae"},"outputs":[{"ename":"NameError","evalue":"name 'test_generator' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-46265aa973d8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#none of this works rn bc of the same reasons(test_generator file is not made)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test accuracy: {test_acc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'test_generator' is not defined"]}],"source":["#none of this works rn bc of the same reasons(test_generator file is not made)\n","test_loss, test_acc = model.evaluate(test_generator)\n","print(f\"Test accuracy: {test_acc}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wa_-ADeh8MB9"},"outputs":[],"source":["! pip install kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ec0EdGXy_pGK"},"outputs":[],"source":["! chmod 600 ~/ .kaggle/kaggle.json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_z3MFSoiAM8C"},"outputs":[],"source":["#import kagglehub\n","\n","## Download latest version\n","#path = kagglehub.dataset_download(\"mylesoneill/tagged-anime-illustrations\")\n","\n","#print(\"Path to dataset files:\", path)"]}],"metadata":{"colab":{"toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}